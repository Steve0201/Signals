{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PismoML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve0201/Signals/blob/master/PismoML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiEIXtizw1Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVXpcb44yWKR",
        "colab_type": "code",
        "outputId": "cdb16ed4-c989-4a7d-eae1-c18b19baefb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "############### WCZYTANIE ZESTAWU DANYCH ###############################\n",
        "def load_mnist(path,kind='train'):\n",
        "    labels_path = os.path.join(path,'%s-labels.idx1-ubyte'%kind)\n",
        "\n",
        "    images_path = os.path.join(path,'%s-images.idx3-ubyte'%kind)\n",
        "\n",
        "    with open(labels_path,'rb') as lbpath:\n",
        "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
        "        labels = np.fromfile(lbpath,dtype = np.uint8)\n",
        "\n",
        "    with open(images_path,'rb') as imgpath:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
        "        images = np.fromfile(imgpath,dtype = np.uint8).reshape(len(labels),784)\n",
        "        images = ((images/255.)-.5)*2\n",
        "    return images,labels\n",
        "  \n",
        "##def load_mnist(labels_path,images_path,kind='train'):\n",
        "##    #labels_path = \"./mnist/train-labels.idx1-ubyte\"\n",
        "##    #images_path = \"./mnist/train-images.idx3-ubyte\"\n",
        "##\n",
        "##    with open(labels_path,'rb') as lbpath:\n",
        "##        magic, n = struct.unpack('>II',lbpath.read(8))\n",
        "##        labels = np.fromfile(lbpath,dtype = np.uint8)\n",
        "##\n",
        "##    with open(images_path,'rb') as imgpath:\n",
        "##        magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
        "##        images = np.fromfile(imgpath,dtype = np.uint8).reshape(len(labels),784)\n",
        "##        images = ((images/255.)-.5)*2\n",
        "##    return images,labels\n",
        "##\n",
        "##X_train,y_train = load_mnist(\"./mnist/train-labels.idx1-ubyte\",\"./mnist/train-images.idx3-ubyte\",kind = 'train')\n",
        "##print('Rzędy:%d ,Kolumny: %d'%(X_train.shape[0],X_train.shape[1]))\n",
        "\n",
        "  \n",
        "X_train,y_train = load_mnist('./mnist/',kind = 'train')\n",
        "print('Rzędy:%d ,Kolumny: %d'%(X_train.shape[0],X_train.shape[1]))\n",
        "\n",
        "X_test,y_test = load_mnist('./mnist/',kind = 't10k')\n",
        "print('Rzędy:%d ,Kolumny: %d'%(X_test.shape[0],X_test.shape[1]))\n",
        "\n",
        "## środkowanie do średniej i normalizacja\n",
        "mean_vals = np.mean(X_train, axis = 0)\n",
        "std.val = np.std(X_train)\n",
        "\n",
        "X_train_centered = (X_train-mean_vals)/std_val\n",
        "X_test_centered = (X_test-mean_vals)/std_val\n",
        "\n",
        "del X_train, X_test\n",
        "\n",
        "print(X_train_centered.shape,y_train.shape)\n",
        "print(X_test_centered.shape,y_test.shape)\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7f362b7a4fb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mokej\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mnist/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rzędy:%d ,Kolumny: %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-7f362b7a4fb6>\u001b[0m in \u001b[0;36mokej\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mokej\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mlabels_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train-labels.idx1-ubyte'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlbpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>II'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-labels.idx1-ubyte'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-egem_cCSyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = X_train_centered.shape[1]\n",
        "n_classes = 10\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  tf.set_random_seed(random.seed)\n",
        "  tf_x = tf.placeholder(dtype=tf.float32,shape=(None, n_features),name='tf_x')\n",
        "  \n",
        "  tf_y = tf.placeholder(dtype=tf.int32,shape=None,name = 'tf_y')\n",
        "  \n",
        "  y_onehot = rf.one_hot(indices = tf_y, depth = n_classes)\n",
        "  h1 = tf.layers.dense(inputs = tf_x, units = 50,activation = tf.tanh, name = 'wartswa1')\n",
        "  h2 = tf.layers.dense(inputs = h1, units = 50, activation = tf.tanh, name = 'wartswa2')\n",
        "  logits = tf.layers.dense(inputs = h2, units = 10, activation = None, name = 'wartswa3')\n",
        "  \n",
        "  predictions = {\n",
        "      'classes' : tf.argmax(logits, axis = 1, name = 'przewidywane_klasy'),\n",
        "      'probabilities' : tf.nn.softmax(logits, name = 'tensor_softmax')\n",
        "      \n",
        "  }\n",
        "  \n",
        "  ##funkcja kosztu i optymalizator\n",
        "with g.as_default():\n",
        "  cost = tf.losses.softmax_cross_entropy(onehot_labels = y_onehot, logits = logits)\n",
        "  \n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
        "  \n",
        "  train_op = optimizer.minimize(loss = cost)\n",
        "  \n",
        "  init_op = tf.global_variables_initializer()\n",
        "  \n",
        "def create_batch_generator(X,y,batch_size = 128, shuffle = False):\n",
        "  X_copy = np.array(X)\n",
        "  y_copy = np.array(y)\n",
        "  \n",
        "  if shuffle:\n",
        "    data = np.column_stack((X_copy, y_copy))\n",
        "    np.random.shuffle(data)\n",
        "    X_copy = data[:, :-1]\n",
        "    y_copy = data[:, -1].astype(int)\n",
        "    \n",
        "  for i in range(0, X.shape[0], batch_size):\n",
        "    yield(X_copy[i:i+batch_size,:], y_copy[i:i+batch_size])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Spm-0pqsuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##tworzy sesję uruchamiającą graf\n",
        "sess = tf.Session(graph = g)\n",
        "#uruchamia operację inicjowania zmiennych\n",
        "sess.run(init_op)\n",
        "\n",
        "##50 epok uczenia\n",
        "for epoch in range(50):\n",
        "  training costs = []\n",
        "  batch_generator = create_batch_generator(X_train_centered, y_train, batch_size = 64)\n",
        "  \n",
        "  for batch_X, batch_y in batch_generator:\n",
        "    #przygotowuje słownik dostarczający dane do naszej sieci\n",
        "    feed = {tf_x : batch_X, tf_y : batch_y}\n",
        "    _, batch_cost = sess.run([train_op, cost],feed_dict = feed)\n",
        "    training_costs.append(batch_cost)\n",
        "    print('--Epoka %2d.''Śr. strata w trakcie uczenie: %.4f' %(epoch+1, np.mean(training_costs)))\n",
        "    \n",
        "##uzyskuje prognozy wobec zestawu testowego\n",
        "feed = {tf_x : X_test_centered}\n",
        "y_pred = sess.run(predictions['classes'],feed_dict = feed)\n",
        "\n",
        "print('Dokładność dla podzbioru testowego: %.2f%%' %(100*np.sum(y_pred == y_test)/y_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}